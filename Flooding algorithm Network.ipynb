{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from random import seed\n",
    "from sklearn import preprocessing\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_lstm(nn.Module):\n",
    "    def __init__(self, lr, input_channels = 1, batch_size = 1, lstm_hidden_size = 512, lstm_layer_size = 2):\n",
    "        super(conv_lstm, self).__init__()\n",
    "        self.lr = lr\n",
    "        self.input_channels = input_channels\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #self.height = height\n",
    "        #self.width = width\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm_layer_size = lstm_layer_size\n",
    "        self.conv_layer = nn.Conv2d(in_channels = self.input_channels, out_channels = 10,\n",
    "                                   kernel_size = 3, stride = 1)\n",
    "        conv_layer_init_ = 1.0/np.sqrt(self.conv_layer.weight.data.size()[0])\n",
    "        self.conv_layer.weight.data.uniform_(-conv_layer_init_, conv_layer_init_)\n",
    "        self.conv_layer.bias.data.uniform_(-conv_layer_init_, conv_layer_init_)\n",
    "        self.conv_layer_batchNorm = nn.BatchNorm2d(10)\n",
    "        self.pool = nn.MaxPool2d((2,4), stride=1)#experiment with maxpool/avgpool\n",
    "        #second querry - should i maxpool/avgpool then send to lstm layer or leave it as it is? Refer to paper\n",
    "        \n",
    "        #entirely dependant on convlayer out shape\n",
    "        self.lstm_layer = nn.LSTM(input_size = 5,#check forward shape and last shape: adjust accordingly\n",
    "                                 hidden_size = self.lstm_hidden_size,\n",
    "                                 num_layers  = self.lstm_layer_size,\n",
    "                                 batch_first = True,\n",
    "                                 dropout = 0.1)\n",
    "        \n",
    "        self.fc_layer = nn.Linear(self.lstm_hidden_size, 10)#10 to represebt feature length\n",
    "        fc_init_ = 1.0/np.sqrt(self.fc_layer.weight.data.size()[0])\n",
    "        #initialize weights and biases\n",
    "        self.fc_layer.weight.data.uniform_(-fc_init_, fc_init_)\n",
    "        self.fc_layer.bias.data.uniform_(-fc_init_, fc_init_)\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, frames):\n",
    "        x = self.conv_layer(frames)\n",
    "        x = self.conv_layer_batchNorm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.squeeze()\n",
    "        batch_size = x.size(0)\n",
    "        hidden_state = torch.zeros(self.lstm_layer_size, \n",
    "                                  batch_size,\n",
    "                                  self.lstm_hidden_size).to(self.device)\n",
    "        cell_state = torch.zeros(self.lstm_layer_size,\n",
    "                                batch_size,\n",
    "                                self.lstm_hidden_size).to(self.device)\n",
    "        hidden_lstm_layer = (hidden_state, cell_state)\n",
    "        out, (hn,cn) = self.lstm_layer(x,(hidden_state, cell_state))\n",
    "        \n",
    "        #print(\"lstm_out shape: \", out.shape)\n",
    "        modified_out = out[:, -1, :]\n",
    "        fc_out = self.fc_layer(modified_out)\n",
    "        return fc_out, out, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_loss_graph(epoch_array, loss_array):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, criterion, epochs=10):\n",
    "    loss_array = []\n",
    "    epoch_array = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            #print((inputs.type()))\n",
    "            inputs = inputs.type(torch.FloatTensor)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            #print((inputs.type()))\n",
    "            predictions,_,__ = model(inputs)\n",
    "            print(predictions.size(), labels.squeeze().size())\n",
    "            loss_ = criterion(predictions, labels.squeeze())\n",
    "            loss_.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss_.item()*inputs.size(0) \n",
    "        print(running_loss)\n",
    "        loss_array.append(running_loss/len(dataloader.dataset))\n",
    "        epoch_array.append(epoch)\n",
    "    return loss_array, epoch_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data_loader, criterion, epochs = 1):\n",
    "    y_true = []\n",
    "    y_preds = []\n",
    "    with torch.no_grad():\n",
    "        for epoch in range(epochs):\n",
    "                running_loss = 0.0\n",
    "                for inputs, labels in data_loader:\n",
    "                    inputs = inputs.type(torch.FloatTensor)\n",
    "                    labels = labels.type(torch.FloatTensor)\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs,_,__ = model(inputs)\n",
    "                    #print(\"labels: \", labels.shape)\n",
    "                    #print(\"outputs: \", outputs.shape)\n",
    "                    loss = criterion(outputs, labels.squeeze())\n",
    "                                            \n",
    "                    running_loss+=loss.item()*inputs.size(0)                    \n",
    "                    #print(\"preds: \", preds, \" targets: \", targets)\n",
    "                    #print(y_true.shape)\n",
    "                    labels = labels.squeeze()\n",
    "                    y_true.append(labels.detach().cpu().numpy())\n",
    "                    y_preds.append(outputs.detach().cpu().numpy())\n",
    "                    \n",
    "                print(\"epoch: \",epoch)\n",
    "                print(\"loss: \",running_loss/len(data_loader.dataset))\n",
    "    return y_true, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_lstm(lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conv_lstm(\n",
       "  (conv_layer): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv_layer_batchNorm): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=(2, 4), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (lstm_layer): LSTM(5, 512, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (fc_layer): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_ = torch.rand(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_.shape#B,C,H,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_ = tensor_.unsqueeze(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_, _,__= model(tensor_.to(\"cpu\"))\n",
    "out_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement dataloader\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how do i wanna load data?\n",
    "#input: frame one\n",
    "#output(label): frame 2\n",
    "import ipynb.fs.full.Flood_dataloader as Flood_dataloader\n",
    "import os\n",
    "#file_       = 'conv_lstm.csv'\n",
    "file_       = os.path.join(\"csv_files/\", \"convlstm.csv\")\n",
    "root_input  = 'frame_tensors/'\n",
    "root_output = 'frame_output_tensors/'\n",
    "dataset = Flood_dataloader.conv_lstm_dataloader(file_, root_input, root_output)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_x = 48\n",
    "split_y = 30\n",
    "#split_x = 191\n",
    "#split_y = 5\n",
    "batch_size = 1\n",
    "train_set, test_set = torch.utils.data.random_split(dataset,[split_x,split_y])\n",
    "train_loader = DataLoader(dataset=train_set, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2272/4053768150.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2272/3880274794.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, optimizer, criterion, epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mloss_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\scowt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\scowt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_values, y_values = train_model(model, train_loader, optimizer, criterion, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.103654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049086</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037397</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.031930</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  epoch\n",
       "0  0.103654      0\n",
       "1  0.065112      1\n",
       "2  0.049086      2\n",
       "3  0.037397      3\n",
       "4  0.031930      4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "data1 = {'loss':x_values,'epoch':y_values}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6,3) #set plot size\n",
    "plt3 = sns.lineplot(x=\"epoch\", y=\"loss\", data=df1) #blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "labels:  torch.Size([1, 1, 10, 10])\n",
      "outputs:  torch.Size([10, 10])\n",
      "epoch:  0\n",
      "loss:  0.02052800728318592\n"
     ]
    }
   ],
   "source": [
    "tr,pr = test_model(model, test_loader, criterion, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_np = np.array(tr)\n",
    "pr_np = np.array(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in range(len(tr_np)):\n",
    "    norm_ = scaler.minmax_scale(tr_np[data],feature_range=(0,255))\n",
    "    tr_np[data] = norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in range(len(pr_np)):\n",
    "    norm_ = scaler.minmax_scale(pr_np[data],feature_range=(0,255))\n",
    "    pr_np[data] = norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1, 10, 10) (30, 1, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "tr_np = np.expand_dims(tr_np, axis=1)\n",
    "pr_np = np.expand_dims(pr_np, axis=1)\n",
    "print(tr_np.shape, pr_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 10, 10, 1) (30, 10, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "tr_np = tr_np.transpose(0,2,3,1)\n",
    "pr_np = pr_np.transpose(0,2,3,1)\n",
    "print(tr_np.shape, pr_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file true_data.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageSequenceClip\n",
    "clip = ImageSequenceClip(list(tr_np), fps=3)\n",
    "clip.write_gif('true_data.gif', fps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file preicted_data.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageSequenceClip\n",
    "clip = ImageSequenceClip(list(pr_np), fps=3)\n",
    "clip.write_gif('preicted_data.gif', fps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.07673538e+00,  9.85126495e-02,  8.97179842e-01,\n",
       "         1.08610487e+00,  5.81517816e-03,  5.22624850e-02,\n",
       "         1.86553076e-02,  8.00375417e-02,  3.18029374e-02,\n",
       "         2.36323833e-01],\n",
       "       [ 9.69692618e-02,  3.60730886e-01,  7.84743607e-01,\n",
       "         2.37492472e-01,  7.18802214e-01,  1.60193935e-01,\n",
       "         6.97658733e-02,  2.89516240e-01,  4.95440587e-02,\n",
       "         2.00459883e-01],\n",
       "       [ 3.08258869e-02,  4.41867769e-01,  2.98427820e-01,\n",
       "         7.23619401e-01,  1.65910035e-01,  4.63694036e-02,\n",
       "         1.07002474e-01,  5.74903078e-02,  1.71947777e-02,\n",
       "         6.26910180e-02],\n",
       "       [ 1.14961350e+00,  1.25950122e+00,  1.06955540e+00,\n",
       "         1.25855505e-01,  8.43452066e-02,  1.06693590e+00,\n",
       "         1.37317702e-01, -1.14614181e-01,  1.20636475e+00,\n",
       "         1.14666462e+00],\n",
       "       [ 7.04396218e-02,  2.41696164e-01,  3.31563652e-01,\n",
       "         1.77774653e-01,  2.05930263e-01,  4.48351949e-02,\n",
       "         1.76013172e-01,  2.35307410e-01,  1.80200264e-02,\n",
       "         7.57383406e-02],\n",
       "       [ 2.36436799e-02,  5.25819212e-02,  8.48721564e-02,\n",
       "         2.32498825e-01,  1.19799122e-01, -2.94868648e-03,\n",
       "         1.83900625e-01,  6.05988026e-01, -4.58468944e-02,\n",
       "         2.20987797e-02],\n",
       "       [ 1.04885593e-01,  3.53131443e-01,  1.31284282e-01,\n",
       "         1.44627959e-01,  2.01768577e-01, -6.31524622e-03,\n",
       "         1.74790606e-01,  1.35836229e-01, -4.10743877e-02,\n",
       "        -1.16727352e-02],\n",
       "       [-2.54137814e-02,  1.17283747e-01,  2.99406499e-02,\n",
       "         1.10463500e-02,  1.19836882e-01,  2.29184777e-02,\n",
       "         1.36594519e-01,  5.48014864e-02, -6.05536997e-03,\n",
       "        -6.28188252e-04],\n",
       "       [-9.61042047e-02,  2.24007070e-02,  8.71600583e-02,\n",
       "         1.23947948e-01,  1.79954559e-01,  3.03034186e-02,\n",
       "         9.59175378e-02,  5.61202466e-02, -4.27962914e-02,\n",
       "        -3.15163359e-02],\n",
       "       [-8.90677273e-02, -2.15324014e-03,  2.34339610e-01,\n",
       "         6.39674962e-02,  3.53385925e-01,  2.80438513e-02,\n",
       "         1.13522023e-01,  4.31407243e-02, -4.11972851e-02,\n",
       "        -4.15276363e-03]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as scaler\n",
    "#scaler.minmax_scale(pr[1].squeeze(),feature_range=(0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fgds = pd.read_csv(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Inputs</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.pt</td>\n",
       "      <td>0.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.pt</td>\n",
       "      <td>1.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.pt</td>\n",
       "      <td>2.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.pt</td>\n",
       "      <td>3.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.pt</td>\n",
       "      <td>4.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>73.pt</td>\n",
       "      <td>73.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>74.pt</td>\n",
       "      <td>74.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>75.pt</td>\n",
       "      <td>75.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>76.pt</td>\n",
       "      <td>76.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>77.pt</td>\n",
       "      <td>77.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 Inputs Labels\n",
       "0            0   0.pt   0.pt\n",
       "1            1   1.pt   1.pt\n",
       "2            2   2.pt   2.pt\n",
       "3            3   3.pt   3.pt\n",
       "4            4   4.pt   4.pt\n",
       "..         ...    ...    ...\n",
       "73          73  73.pt  73.pt\n",
       "74          74  74.pt  74.pt\n",
       "75          75  75.pt  75.pt\n",
       "76          76  76.pt  76.pt\n",
       "77          77  77.pt  77.pt\n",
       "\n",
       "[78 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
