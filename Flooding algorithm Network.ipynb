{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from random import seed\n",
    "from sklearn import preprocessing\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_lstm(nn.Module):\n",
    "    def __init__(self, lr, input_channels = 1, batch_size = 1, lstm_hidden_size = 512, lstm_layer_size = 2):\n",
    "        super(conv_lstm, self).__init__()\n",
    "        self.lr = lr\n",
    "        self.input_channels = input_channels\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #self.height = height\n",
    "        #self.width = width\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm_layer_size = lstm_layer_size\n",
    "        self.conv_layer = nn.Conv2d(in_channels = self.input_channels, out_channels = 10,\n",
    "                                   kernel_size = 3, stride = 1)\n",
    "        conv_layer_init_ = 1.0/np.sqrt(self.conv_layer.weight.data.size()[0])\n",
    "        self.conv_layer.weight.data.uniform_(-conv_layer_init_, conv_layer_init_)\n",
    "        self.conv_layer.bias.data.uniform_(-conv_layer_init_, conv_layer_init_)\n",
    "        self.conv_layer_batchNorm = nn.BatchNorm2d(10)\n",
    "        self.pool = nn.MaxPool2d((2,4), stride=1)#experiment with maxpool/avgpool\n",
    "        #second querry - should i maxpool/avgpool then send to lstm layer or leave it as it is? Refer to paper\n",
    "        \n",
    "        #entirely dependant on convlayer out shape\n",
    "        self.lstm_layer = nn.LSTM(input_size = 5,#check forward shape and last shape: adjust accordingly\n",
    "                                 hidden_size = self.lstm_hidden_size,\n",
    "                                 num_layers  = self.lstm_layer_size,\n",
    "                                 batch_first = True,\n",
    "                                 dropout = 0.1)\n",
    "        \n",
    "        self.fc_layer = nn.Linear(self.lstm_hidden_size, 10)#10 to represebt feature length\n",
    "        fc_init_ = 1.0/np.sqrt(self.fc_layer.weight.data.size()[0])\n",
    "        #initialize weights and biases\n",
    "        self.fc_layer.weight.data.uniform_(-fc_init_, fc_init_)\n",
    "        self.fc_layer.bias.data.uniform_(-fc_init_, fc_init_)\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, frames):\n",
    "        x = self.conv_layer(frames)\n",
    "        x = self.conv_layer_batchNorm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.squeeze()\n",
    "        batch_size = x.size(0)\n",
    "        hidden_state = torch.zeros(self.lstm_layer_size, \n",
    "                                  batch_size,\n",
    "                                  self.lstm_hidden_size).to(self.device)\n",
    "        cell_state = torch.zeros(self.lstm_layer_size,\n",
    "                                batch_size,\n",
    "                                self.lstm_hidden_size).to(self.device)\n",
    "        hidden_lstm_layer = (hidden_state, cell_state)\n",
    "        out, (hn,cn) = self.lstm_layer(x,(hidden_state, cell_state))\n",
    "        \n",
    "        #print(\"lstm_out shape: \", out.shape)\n",
    "        modified_out = out[:, -1, :]\n",
    "        fc_out = self.fc_layer(modified_out)\n",
    "        return fc_out, out, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_lstm(lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conv_lstm(\n",
       "  (conv_layer): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv_layer_batchNorm): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=(2, 4), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (lstm_layer): LSTM(5, 512, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (fc_layer): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_ = torch.rand(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 10])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_.shape#B,C,H,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_ = tensor_.unsqueeze(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_, _,__= model(tensor_.to(\"cpu\"))\n",
    "out_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement dataloader\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how do i wanna load data?\n",
    "#input: frame one\n",
    "#output(label): frame 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
