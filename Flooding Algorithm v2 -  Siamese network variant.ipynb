{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f1cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from random import seed\n",
    "from sklearn import preprocessing\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f5666a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class siamese(nn.Module):\n",
    "    def __init__(self, lr=0.001, input_channels = 1, batch_size = 1, lstm_hidden_size = 512, lstm_layer_size = 2):\n",
    "        super(siamese, self).__init__()\n",
    "        self.lr = lr\n",
    "        self.input_channels = input_channels\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #self.height = height\n",
    "        #self.width = width\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm_layer_size = lstm_layer_size\n",
    "        \n",
    "        self.conv_layer = nn.Conv2d(in_channels = self.input_channels, out_channels = 10,\n",
    "                                   kernel_size = 3, stride = 1)\n",
    "        conv_layer_init_ = 1.0/np.sqrt(self.conv_layer.weight.data.size()[0])\n",
    "        self.conv_layer.weight.data.uniform_(-conv_layer_init_, conv_layer_init_)\n",
    "        self.conv_layer.bias.data.uniform_(-conv_layer_init_, conv_layer_init_)\n",
    "        self.conv_layer_batchNorm = nn.BatchNorm2d(10)\n",
    "        self.pool = nn.AvgPool2d((2,4), stride=1)#experiment with maxpool/avgpool\n",
    "        #second querry - should i maxpool/avgpool then send to lstm layer or leave it as it is? Refer to paper\n",
    "        \n",
    "        \n",
    "        self.conv_layer1 = nn.Conv2d(in_channels = 10, out_channels = 10,\n",
    "                                   kernel_size = 2, stride = 1)\n",
    "        conv_layer_init_1 = 1.0/np.sqrt(self.conv_layer1.weight.data.size()[0])\n",
    "        self.conv_layer1.weight.data.uniform_(-conv_layer_init_1, conv_layer_init_1)\n",
    "        self.conv_layer1.bias.data.uniform_(-conv_layer_init_1, conv_layer_init_1)\n",
    "        self.conv_layer_batchNorm1 = nn.BatchNorm2d(10)\n",
    "        self.pool1 = nn.AvgPool2d((2,2), stride=1)#experiment with maxpool/avgpool\n",
    "        \n",
    "        \n",
    "        \n",
    "        #entirely dependant on convlayer out shape\n",
    "        self.lstm_layer = nn.LSTM(input_size = 3,#check forward shape and last shape: adjust accordingly\n",
    "                                 hidden_size = self.lstm_hidden_size,\n",
    "                                 num_layers  = self.lstm_layer_size,\n",
    "                                 batch_first = True,\n",
    "                                 dropout = 0.2)\n",
    "        \n",
    "        self.lstm_layer1 = nn.LSTM(input_size = 512,#check forward shape and last shape: adjust accordingly\n",
    "                                 hidden_size = self.lstm_hidden_size,\n",
    "                                 num_layers  = self.lstm_layer_size,\n",
    "                                 batch_first = True,\n",
    "                                 dropout = 0.05)\n",
    "        \n",
    "        \n",
    "        self.fc_layer = nn.Linear(self.lstm_hidden_size, self.lstm_hidden_size)#10 to represebt feature length\n",
    "        fc_init_ = 1.0/np.sqrt(self.fc_layer.weight.data.size()[0])\n",
    "        #initialize weights and biases\n",
    "        self.fc_layer.weight.data.uniform_(-fc_init_, fc_init_)\n",
    "        self.fc_layer.bias.data.uniform_(-fc_init_, fc_init_)\n",
    "        \n",
    "        self.fc_layer1 = nn.Linear(self.lstm_hidden_size, 10)\n",
    "        fc_init_1 = 1.0/np.sqrt(self.fc_layer1.weight.data.size()[0])\n",
    "        self.fc_layer1.weight.data.uniform_(-fc_init_1, fc_init_1)\n",
    "        self.fc_layer1.bias.data.uniform_(-fc_init_1, fc_init_1)\n",
    "        \n",
    "        self.ln = nn.LayerNorm(self.lstm_hidden_size)\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, frames):\n",
    "        x = self.conv_layer(frames)\n",
    "        x = self.conv_layer_batchNorm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        \n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.conv_layer_batchNorm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        #print(\"c_Out: \",x.shape)\n",
    "        x = x.squeeze()\n",
    "        batch_size = x.size(0)\n",
    "        hidden_state = torch.zeros(self.lstm_layer_size, \n",
    "                                  batch_size,\n",
    "                                  self.lstm_hidden_size).to(self.device)\n",
    "        cell_state = torch.zeros(self.lstm_layer_size,\n",
    "                                batch_size,\n",
    "                                self.lstm_hidden_size).to(self.device)\n",
    "        hidden_lstm_layer = (hidden_state, cell_state)\n",
    "        \n",
    "        #print(\"conv: \", x.shape)\n",
    "        out, (hn,cn) = self.lstm_layer(x,(hidden_state, cell_state))\n",
    "        #print(\"lstm: \",out.shape)\n",
    "        out, (hn,cn) = self.lstm_layer1(out,(hidden_state, cell_state))\n",
    "        \n",
    "        #print(\"lstm_out shape: \", out.shape)\n",
    "        modified_out = out[:, -1, :]\n",
    "        fc_out = self.fc_layer(modified_out)\n",
    "        fc_out = self.ln(fc_out)\n",
    "        fc_out = F.relu(fc_out)\n",
    "        fc_out = self.fc_layer1(fc_out)\n",
    "        return fc_out, out, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1245d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class siamese1(nn.Module):\n",
    "    def __init__(self, lr=0.001, input_channels = 1, batch_size = 1, lstm_hidden_size = 512, lstm_layer_size = 2):\n",
    "        super(siamese1, self).__init__()\n",
    "        self.lr = lr\n",
    "        self.input_channels = input_channels\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #self.height = height\n",
    "        #self.width = width\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm_layer_size = lstm_layer_size\n",
    "        \n",
    "        self.conv_layer = nn.Conv2d(in_channels = self.input_channels, out_channels = 10,\n",
    "                                   kernel_size = 3, stride = 1)\n",
    "        self.conv_layer_batchNorm = nn.BatchNorm2d(10)\n",
    "        self.pool = nn.AvgPool2d((2,4), stride=1)#experiment with maxpool/avgpool\n",
    "        #second querry - should i maxpool/avgpool then send to lstm layer or leave it as it is? Refer to paper\n",
    "        \n",
    "        \n",
    "        self.conv_layer1 = nn.Conv2d(in_channels = 10, out_channels = 10,\n",
    "                                   kernel_size = 2, stride = 1)\n",
    "        conv_layer_init_1 = 1.0/np.sqrt(self.conv_layer1.weight.data.size()[0])\n",
    "        self.conv_layer1.weight.data.uniform_(-conv_layer_init_1, conv_layer_init_1)\n",
    "        self.conv_layer1.bias.data.uniform_(-conv_layer_init_1, conv_layer_init_1)\n",
    "        self.conv_layer_batchNorm1 = nn.BatchNorm2d(10)\n",
    "        self.pool1 = nn.AvgPool2d((2,2), stride=1)#experiment with maxpool/avgpool\n",
    "        \n",
    "        \n",
    "        \n",
    "        #entirely dependant on convlayer out shape\n",
    "        self.lstm_layer = nn.LSTM(input_size = 3,#check forward shape and last shape: adjust accordingly\n",
    "                                 hidden_size = self.lstm_hidden_size,\n",
    "                                 num_layers  = self.lstm_layer_size,\n",
    "                                 batch_first = True,\n",
    "                                 dropout = 0.2)\n",
    "        \n",
    "        self.lstm_layer1 = nn.LSTM(input_size = 512,#check forward shape and last shape: adjust accordingly\n",
    "                                 hidden_size = self.lstm_hidden_size,\n",
    "                                 num_layers  = self.lstm_layer_size,\n",
    "                                 batch_first = True,\n",
    "                                 dropout = 0.05)\n",
    "        \n",
    "        \n",
    "        self.fc_layer = nn.Linear(self.lstm_hidden_size, self.lstm_hidden_size)#10 to represebt feature length\n",
    "        fc_init_ = 1.0/np.sqrt(self.fc_layer.weight.data.size()[0])\n",
    "        #initialize weights and biases\n",
    "        self.fc_layer.weight.data.uniform_(-fc_init_, fc_init_)\n",
    "        self.fc_layer.bias.data.uniform_(-fc_init_, fc_init_)\n",
    "        \n",
    "        self.fc_layer1 = nn.Linear(self.lstm_hidden_size, 10)\n",
    "        \n",
    "        self.ln = nn.LayerNorm(self.lstm_hidden_size)\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, frames):\n",
    "        x = self.conv_layer(frames)\n",
    "        x = self.conv_layer_batchNorm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        \n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.conv_layer_batchNorm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        #print(\"c_Out: \",x.shape)\n",
    "        x = x.squeeze()\n",
    "        batch_size = x.size(0)\n",
    "        hidden_state = torch.zeros(self.lstm_layer_size, \n",
    "                                  batch_size,\n",
    "                                  self.lstm_hidden_size).to(self.device)\n",
    "        cell_state = torch.zeros(self.lstm_layer_size,\n",
    "                                batch_size,\n",
    "                                self.lstm_hidden_size).to(self.device)\n",
    "        hidden_lstm_layer = (hidden_state, cell_state)\n",
    "        \n",
    "        #print(\"conv: \", x.shape)\n",
    "        out, (hn,cn) = self.lstm_layer(x,(hidden_state, cell_state))\n",
    "        #print(\"lstm: \",out.shape)\n",
    "        out, (hn,cn) = self.lstm_layer1(out,(hidden_state, cell_state))\n",
    "        \n",
    "        #print(\"lstm_out shape: \", out.shape)\n",
    "        modified_out = out[:, -1, :]\n",
    "        fc_out = self.fc_layer(modified_out)\n",
    "        fc_out = self.ln(fc_out)\n",
    "        fc_out = F.relu(fc_out)\n",
    "        fc_out = self.fc_layer1(fc_out)\n",
    "        return fc_out, out, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96a2e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_siamese = siamese()\n",
    "model_siamese1 = siamese1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a1bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
